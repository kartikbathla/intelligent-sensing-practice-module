{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETR Smoke Detection Training on Pyronear Dataset (Colab Ready)\n",
    "\n",
    "This notebook trains a [facebook/detr-resnet-50](https://huggingface.co/facebook/detr-resnet-50) model on the Pyronear smoke dataset, downloading data directly from Hugging Face. It uses PyTorch Lightning and torchmetrics to provide detailed YOLO-style metrics (mAP@0.5, mAP@0.5:0.95, precision, recall, etc.) during training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision pytorch-lightning torchmetrics transformers datasets huggingface_hub pycocotools opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Download Pyronear Dataset from Hugging Face\n",
    "We use the [datasets](https://huggingface.co/docs/datasets) library to download the Pyronear smoke dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the correct dataset repo if needed\n",
    "dataset = load_dataset('pyronear/smoke-detection-yolo', split='train')\n",
    "# If the dataset is not in COCO format, conversion logic will be added below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÅ Convert YOLO to COCO format (if needed)\n",
    "If the dataset is in YOLO format, convert it to COCO format for DETR compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your YOLO-to-COCO conversion code here, or skip if dataset is already in COCO format.\n",
    "# Example placeholder:\n",
    "# coco_dict = convert_yolo_to_coco(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Prepare DataLoaders\n",
    "Wrap the COCO dataset for use with PyTorch Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example DataLoader setup (replace with your actual paths and logic)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = CocoDetection(img_folder, ann_file, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2, collate_fn=lambda x: tuple(zip(*x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° PyTorch Lightning Module with YOLO-style Metrics\n",
    "We use torchmetrics' MeanAveragePrecision for mAP@0.5, mAP@0.5:0.95, precision, recall, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DETRLightningModule(pl.LightningModule):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = DetrForObjectDetection.from_pretrained('facebook/detr-resnet-50', num_labels=num_classes)\n",
    "        self.processor = DetrImageProcessor.from_pretrained('facebook/detr-resnet-50')\n",
    "        self.map_metric = MeanAveragePrecision(class_metrics=True)\n",
    "\n",
    "    def forward(self, pixel_values):\n",
    "        return self.model(pixel_values)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        encoding = self.processor(images, return_tensors=\"pt\", padding=True).to(self.device)\n",
    "        labels = [{\"class_labels\": t['labels'], \"boxes\": t['boxes']} for t in targets]\n",
    "        outputs = self.model(**encoding, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        # Calculate metrics\n",
    "        preds = outputs.logits\n",
    "        # You may need to post-process predictions for torchmetrics\n",
    "        self.map_metric.update(preds, labels)\n",
    "        self.log_dict(self.map_metric.compute(), prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        encoding = self.processor(images, return_tensors=\"pt\", padding=True).to(self.device)\n",
    "        labels = [{\"class_labels\": t['labels'], \"boxes\": t['boxes']} for t in targets]\n",
    "        outputs = self.model(**encoding, labels=labels)\n",
    "        preds = outputs.logits\n",
    "        self.map_metric.update(preds, labels)\n",
    "        self.log_dict(self.map_metric.compute(), prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÇ Train the Model\n",
    "Set up the PyTorch Lightning Trainer and start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (replace with your actual dataloader and num_classes)\n",
    "model = DETRLightningModule(num_classes=2)\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator='gpu' if torch.cuda.is_available() else 'cpu')\n",
    "trainer.fit(model, train_dataloader, val_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Visualize Metrics and Predictions\n",
    "Plot or print the metrics after each epoch, and visualize sample predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Plot mAP, Precision, and Recall per epoch from Lightning logs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics(trainer):\n",
    "    # Extract metrics from the trainer's logger\n",
    "    metrics = trainer.callback_metrics\n",
    "    epochs = range(1, trainer.current_epoch + 2)\n",
    "\n",
    "    # These keys may differ depending on your metric names/logs\n",
    "    mAP_50 = [metrics.get(f\"map_50_epoch_{e}\", None) for e in range(trainer.current_epoch + 1)]\n",
    "    mAP_95 = [metrics.get(f\"map_epoch_{e}\", None) for e in range(trainer.current_epoch + 1)]\n",
    "    precision = [metrics.get(f\"precision_epoch_{e}\", None) for e in range(trainer.current_epoch + 1)]\n",
    "    recall = [metrics.get(f\"recall_epoch_{e}\", None) for e in range(trainer.current_epoch + 1)]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, mAP_50, label=\"mAP@0.5\")\n",
    "    plt.plot(epochs, mAP_95, label=\"mAP@0.5:0.95\")\n",
    "    plt.plot(epochs, precision, label=\"Precision\")\n",
    "    plt.plot(epochs, recall, label=\"Recall\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Metric Value\")\n",
    "    plt.title(\"Detection Metrics per Epoch\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Usage example (run after training):\n",
    "# plot_metrics(trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353bcbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üñºÔ∏è Visualize sample predictions from the trained model\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_predictions(model, processor, dataloader, device, class_names, num_images=4, score_threshold=0.5):\n",
    "    model.eval()\n",
    "    images_shown = 0\n",
    "\n",
    "    for images, targets in dataloader:\n",
    "        # Move images to device\n",
    "        pixel_values = processor(images, return_tensors=\"pt\", padding=True).pixel_values.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(pixel_values=pixel_values)\n",
    "\n",
    "        # Post-process outputs\n",
    "        results = processor.post_process_object_detection(outputs, target_sizes=[img.size[::-1] for img in images], threshold=score_threshold)\n",
    "\n",
    "        for idx, (image, result) in enumerate(zip(images, results)):\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.imshow(image)\n",
    "            ax = plt.gca()\n",
    "            boxes = result[\"boxes\"].cpu().numpy()\n",
    "            scores = result[\"scores\"].cpu().numpy()\n",
    "            labels = result[\"labels\"].cpu().numpy()\n",
    "\n",
    "            for box, score, label in zip(boxes, scores, labels):\n",
    "                xmin, ymin, xmax, ymax = box\n",
    "                ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color='red', linewidth=2))\n",
    "                ax.text(xmin, ymin, f'{class_names[label]}: {score:.2f}', bbox=dict(facecolor='yellow', alpha=0.5), fontsize=10, color='black')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            images_shown += 1\n",
    "            if images_shown >= num_images:\n",
    "                return\n",
    "\n",
    "# Usage example (after training):\n",
    "# class_names = [\"background\", \"smoke\"]  # adjust as needed\n",
    "# plot_predictions(model.model, model.processor, val_dataloader, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", class_names=class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
