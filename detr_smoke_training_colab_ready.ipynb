{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ucOnAGvKXbKk",
      "metadata": {
        "id": "ucOnAGvKXbKk"
      },
      "source": [
        "# DETR Smoke Detection Training on Pyronear Dataset (Colab Ready)\n",
        "\n",
        "This notebook trains a [facebook/detr-resnet-50](https://huggingface.co/facebook/detr-resnet-50) model on the Pyronear smoke dataset, downloading data directly from Hugging Face. It uses PyTorch Lightning and torchmetrics to provide detailed YOLO-style metrics (mAP@0.5, mAP@0.5:0.95, precision, recall, etc.) during training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I4UP86aSXbKl",
      "metadata": {
        "id": "I4UP86aSXbKl"
      },
      "source": [
        "## üì¶ Setup and Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wi9tnI0RXbKm",
      "metadata": {
        "id": "wi9tnI0RXbKm"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision pytorch-lightning torchmetrics transformers datasets huggingface_hub pycocotools opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "l7DSz2OmXbKn",
      "metadata": {
        "id": "l7DSz2OmXbKn"
      },
      "source": [
        "## üìö Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kNKmft3OXbKn",
      "metadata": {
        "id": "kNKmft3OXbKn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision.datasets import CocoDetection\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "import pytorch_lightning as pl\n",
        "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5_r0e4YCXbKo",
      "metadata": {
        "id": "5_r0e4YCXbKo"
      },
      "source": [
        "## üì• Download Pyronear Dataset from Hugging Face\n",
        "We use the [datasets](https://huggingface.co/docs/datasets) library to download the Pyronear smoke dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a27WrepxXbKo",
      "metadata": {
        "id": "a27WrepxXbKo"
      },
      "outputs": [],
      "source": [
        "# Change to the correct dataset repo if needed\n",
        "\n",
        "dataset = load_dataset('pyronear/pyro-sdis', split='train')\n",
        "# If the dataset is not in COCO format, conversion logic will be added below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qUiTW8whns2q",
      "metadata": {
        "id": "qUiTW8whns2q"
      },
      "outputs": [],
      "source": [
        "val_dataset = load_dataset('pyronear/pyro-sdis', split='val')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ke4OchumXbKp",
      "metadata": {
        "id": "Ke4OchumXbKp"
      },
      "source": [
        "## üîÅ Convert YOLO to COCO format (if needed)\n",
        "If the dataset is in YOLO format, convert it to COCO format for DETR compatibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GBu00jqgbUIF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBu00jqgbUIF",
        "outputId": "9123b0ee-9b0e-4807-a6b8-c37e4c9160d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29537/29537 [02:11<00:00, 224.32it/s]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "def convert_yolo_to_coco(dataset, class_list):\n",
        "    coco_dict = {\n",
        "        \"images\": [],\n",
        "        \"annotations\": [],\n",
        "        \"categories\": []\n",
        "    }\n",
        "    annotation_id = 1\n",
        "    for idx, data in enumerate(tqdm(dataset)):\n",
        "        image_id = idx + 1\n",
        "        img = data['image']\n",
        "        width, height = img.size\n",
        "        coco_dict[\"images\"].append({\n",
        "            \"id\": image_id,\n",
        "            \"file_name\": data['image_name'],\n",
        "            \"width\": width,\n",
        "            \"height\": height\n",
        "        })\n",
        "        # Handle multiple annotations per image if needed\n",
        "        annos = data['annotations'].strip().split('\\n')\n",
        "        for anno in annos:\n",
        "            parts = anno.strip().split()\n",
        "            if len(parts) != 5:\n",
        "                continue  # skip malformed lines\n",
        "            class_id, x_center, y_center, w, h = map(float, parts)\n",
        "            # Convert YOLO to COCO bbox\n",
        "            x = (x_center - w/2) * width\n",
        "            y = (y_center - h/2) * height\n",
        "            w_box = w * width\n",
        "            h_box = h * height\n",
        "            coco_dict[\"annotations\"].append({\n",
        "                \"id\": annotation_id,\n",
        "                \"image_id\": image_id,\n",
        "                \"category_id\": int(class_id) + 1,  # COCO ids start at 1\n",
        "                \"bbox\": [x, y, w_box, h_box],\n",
        "                \"area\": w_box * h_box,\n",
        "                \"iscrowd\": 0\n",
        "            })\n",
        "            annotation_id += 1\n",
        "    # Add categories\n",
        "    for i, name in enumerate(class_list):\n",
        "        coco_dict[\"categories\"].append({\n",
        "            \"id\": i + 1,\n",
        "            \"name\": name\n",
        "        })\n",
        "    return coco_dict\n",
        "\n",
        "# Example usage:\n",
        "class_list = [\"smoke\"]  # Update if you have more classes\n",
        "coco_dict = convert_yolo_to_coco(dataset, class_list)\n",
        "\n",
        "\n",
        "# Save to file if needed:\n",
        "with open(\"annotations.json\", \"w\") as f:\n",
        "    json.dump(coco_dict, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fD36q6i9n2c_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD36q6i9n2c_",
        "outputId": "839547ec-10de-4f5b-eaa2-220ade201fd1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4099/4099 [00:18<00:00, 224.86it/s]\n"
          ]
        }
      ],
      "source": [
        "coco_dict_val = convert_yolo_to_coco(val_dataset, class_list=class_list)\n",
        "# Save to file if needed:\n",
        "with open(\"annotations.json\", \"w\") as f:\n",
        "    json.dump(coco_dict_val, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5CkP6o3MXbKp",
      "metadata": {
        "id": "5CkP6o3MXbKp"
      },
      "source": [
        "## üóÇÔ∏è Prepare DataLoaders\n",
        "Wrap the COCO dataset for use with PyTorch Lightning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9YaY-I4XmLeW",
      "metadata": {
        "id": "9YaY-I4XmLeW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NrX5LX9AXbKq",
      "metadata": {
        "id": "NrX5LX9AXbKq"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class InMemoryCocoDataset(Dataset):\n",
        "    def __init__(self, dataset, coco_dict, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.coco_dict = coco_dict\n",
        "        self.transform = transform\n",
        "        # Map image_id to annotations\n",
        "        self.ann_map = {}\n",
        "        for ann in coco_dict['annotations']:\n",
        "            self.ann_map.setdefault(ann['image_id'], []).append(ann)\n",
        "        # List of images\n",
        "        self.images = coco_dict['images']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_info = self.images[idx]\n",
        "        image_id = img_info['id']\n",
        "        img = self.dataset[idx]['image']\n",
        "        anns = self.ann_map.get(image_id, [])\n",
        "        if len(anns) > 0:\n",
        "            boxes = torch.tensor([ann['bbox'] for ann in anns], dtype=torch.float32)\n",
        "            labels = torch.tensor([ann['category_id'] for ann in anns], dtype=torch.int64)\n",
        "        else:\n",
        "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            labels = torch.zeros((0,), dtype=torch.int64)\n",
        "        target = {\n",
        "            'boxes': boxes,\n",
        "            'labels': labels\n",
        "        }\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, target\n",
        "\n",
        "# Usage:\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "custom_dataset = InMemoryCocoDataset(dataset, coco_dict, transform=transform)\n",
        "dataloader = DataLoader(custom_dataset, batch_size=4, shuffle=True, num_workers=2, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "custom_dataset_val = InMemoryCocoDataset(val_dataset, coco_dict_val, transform=transform)\n",
        "val_dataloader = DataLoader(custom_dataset_val, batch_size=4, shuffle=True, num_workers=2, collate_fn=lambda x: tuple(zip(*x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3_k69ZE9XbKq",
      "metadata": {
        "id": "3_k69ZE9XbKq"
      },
      "source": [
        "## ‚ö° PyTorch Lightning Module with YOLO-style Metrics\n",
        "We use torchmetrics' MeanAveragePrecision for mAP@0.5, mAP@0.5:0.95, precision, recall, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k6ilqa3eXbKq",
      "metadata": {
        "id": "k6ilqa3eXbKq"
      },
      "outputs": [],
      "source": [
        "from transformers import DetrForObjectDetection, DetrConfig, DetrImageProcessor\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
        "\n",
        "class DETRLightningModule(pl.LightningModule):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        # Load config and set num_labels\n",
        "        config = DetrConfig.from_pretrained('facebook/detr-resnet-50')\n",
        "        config.num_labels = num_classes\n",
        "        self.model = DetrForObjectDetection.from_pretrained(\n",
        "            'facebook/detr-resnet-50', config=config, ignore_mismatched_sizes=True\n",
        "        )\n",
        "        self.processor = DetrImageProcessor.from_pretrained('facebook/detr-resnet-50')\n",
        "        self.map_metric = MeanAveragePrecision(class_metrics=True)\n",
        "\n",
        "    def forward(self, pixel_values):\n",
        "        return self.model(pixel_values)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images, targets = batch\n",
        "        encoding = self.processor(images, return_tensors=\"pt\").to(self.device)\n",
        "        labels = [{\"class_labels\": t['labels'], \"boxes\": t['boxes']} for t in targets]\n",
        "        outputs = self.model(**encoding, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Handle target sizes for PIL or tensor images\n",
        "        if isinstance(images[0], torch.Tensor):\n",
        "            target_sizes = torch.stack([torch.tensor(img.shape[-2:]) for img in images]).to(self.device)\n",
        "        else:\n",
        "            target_sizes = torch.tensor([img.size[::-1] for img in images]).to(self.device)\n",
        "\n",
        "        results = self.processor.post_process_object_detection(\n",
        "            outputs, target_sizes=target_sizes, threshold=0.5\n",
        "        )\n",
        "\n",
        "        # Move predictions to device\n",
        "        for r in results:\n",
        "            r[\"boxes\"] = r[\"boxes\"].to(self.device)\n",
        "            r[\"labels\"] = r[\"labels\"].to(self.device)\n",
        "            r[\"scores\"] = r[\"scores\"].to(self.device)\n",
        "\n",
        "        # Move targets to device\n",
        "        formatted_targets = []\n",
        "        for t in targets:\n",
        "            formatted_targets.append({\n",
        "                \"boxes\": t[\"boxes\"].to(self.device),\n",
        "                \"labels\": t[\"labels\"].to(self.device)\n",
        "            })\n",
        "\n",
        "        self.map_metric.update(results, formatted_targets)\n",
        "        metrics = self.map_metric.compute()\n",
        "        if 'map_per_class' in metrics and isinstance(metrics['map_per_class'], torch.Tensor) and metrics['map_per_class'].numel() > 1:\n",
        "            metrics['map_per_class_mean'] = metrics['map_per_class'][metrics['map_per_class'] != -1].mean().item()\n",
        "            del metrics['map_per_class']\n",
        "        scalar_metrics = {k: (v.item() if isinstance(v, torch.Tensor) and v.numel() == 1 else v) for k, v in metrics.items() if isinstance(v, (float, int)) or (isinstance(v, torch.Tensor) and v.numel() == 1)}\n",
        "        self.log_dict(scalar_metrics, prog_bar=True, on_step=True, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        images, targets = batch\n",
        "        encoding = self.processor(images, return_tensors=\"pt\").to(self.device)\n",
        "        labels = [{\"class_labels\": t['labels'], \"boxes\": t['boxes']} for t in targets]\n",
        "        outputs = self.model(**encoding, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Handle target sizes for PIL or tensor images\n",
        "        if isinstance(images[0], torch.Tensor):\n",
        "            target_sizes = torch.stack([torch.tensor(img.shape[-2:]) for img in images]).to(self.device)\n",
        "        else:\n",
        "            target_sizes = torch.tensor([img.size[::-1] for img in images]).to(self.device)\n",
        "\n",
        "        results = self.processor.post_process_object_detection(\n",
        "            outputs, target_sizes=target_sizes, threshold=0.5\n",
        "        )\n",
        "\n",
        "        # Move predictions to device\n",
        "        for r in results:\n",
        "            r[\"boxes\"] = r[\"boxes\"].to(self.device)\n",
        "            r[\"labels\"] = r[\"labels\"].to(self.device)\n",
        "            r[\"scores\"] = r[\"scores\"].to(self.device)\n",
        "\n",
        "        # Move targets to device\n",
        "        formatted_targets = []\n",
        "        for t in targets:\n",
        "            formatted_targets.append({\n",
        "                \"boxes\": t[\"boxes\"].to(self.device),\n",
        "                \"labels\": t[\"labels\"].to(self.device)\n",
        "            })\n",
        "\n",
        "        self.map_metric.update(results, formatted_targets)\n",
        "        metrics = self.map_metric.compute()\n",
        "        if 'map_per_class' in metrics and isinstance(metrics['map_per_class'], torch.Tensor) and metrics['map_per_class'].numel() > 1:\n",
        "            metrics['map_per_class_mean'] = metrics['map_per_class'][metrics['map_per_class'] != -1].mean().item()\n",
        "            del metrics['map_per_class']\n",
        "        scalar_metrics = {k: (v.item() if isinstance(v, torch.Tensor) and v.numel() == 1 else v) for k, v in metrics.items() if isinstance(v, (float, int)) or (isinstance(v, torch.Tensor) and v.numel() == 1)}\n",
        "        self.log_dict(scalar_metrics, prog_bar=True, on_step=True, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.AdamW(self.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ekqIJbQBXbKr",
      "metadata": {
        "id": "ekqIJbQBXbKr"
      },
      "source": [
        "## üöÇ Train the Model\n",
        "Set up the PyTorch Lightning Trainer and start training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EiYK9qPwvfg4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiYK9qPwvfg4",
        "outputId": "823b60e7-35c0-4215-fd0b-bbd649d16ccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train split length: 29537\n",
            "Train COCO images: 29537\n",
            "Val split length: 4099\n",
            "Val COCO images: 4099\n"
          ]
        }
      ],
      "source": [
        "print(\"Train split length:\", len(dataset))\n",
        "print(\"Train COCO images:\", len(coco_dict['images']))\n",
        "print(\"Val split length:\", len(val_dataset))\n",
        "print(\"Val COCO images:\", len(coco_dict_val['images']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yeI8xGm3XbKr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477,
          "referenced_widgets": [
            "d57248cf39ed4127a4590de6160d7787",
            "0472074cfa124513b46617943ee27aa8",
            "d66eee42c87d4604b4c90969027faf4c",
            "14c2d9979e3847019da1fb3328f5fca6",
            "1738b2fdd8884d26921250288850b17c",
            "d92f92a17fab48a3a776053692294c15",
            "44a961cfcfb64405920150a2d40c823b",
            "815c55147b0e4534bdc6ff5d83b35fca",
            "a6403f74ff1a473eb6fd4434aaec9a4b",
            "fba668a3e644425f98679e6f23af6361",
            "138668df96d8492d9d0347d7f9d5cba6",
            "17f6917c770c487191855e56dd29d0ca",
            "f3c1997eb7d545a88200d739ea692114",
            "9c263877c2c944499f7f775b7110a92a",
            "e9c9fc619365433093964ae52dce4d99",
            "6534cc7812cd41f695cd32c306adab90",
            "769bb51d27524d0bad244ee048850005",
            "58b1a2b123b24db082758785d9851ae7",
            "11eab0cc3d20479986357f4728129d0c",
            "3e6a63ef5f954c3a813ec43bfca7490e",
            "984033a2f5bf4a9d80eed0aa8f33dcce",
            "2cb1bda7b82a4d4e8475a62839b2a0ef"
          ]
        },
        "id": "yeI8xGm3XbKr",
        "outputId": "6df7e36f-6357-4502-92be-abb152da2712"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
            "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DetrForObjectDetection were not initialized from the model checkpoint at facebook/detr-resnet-50 and are newly initialized because the shapes did not match:\n",
            "- class_labels_classifier.bias: found shape torch.Size([92]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
            "- class_labels_classifier.weight: found shape torch.Size([92, 256]) in the checkpoint and torch.Size([3, 256]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name       | Type                   | Params | Mode \n",
            "--------------------------------------------------------------\n",
            "0 | model      | DetrForObjectDetection | 41.5 M | eval \n",
            "1 | map_metric | MeanAveragePrecision   | 0      | train\n",
            "--------------------------------------------------------------\n",
            "41.3 M    Trainable params\n",
            "222 K     Non-trainable params\n",
            "41.5 M    Total params\n",
            "166.008   Total estimated model params size (MB)\n",
            "1         Modules in train mode\n",
            "399       Modules in eval mode\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d57248cf39ed4127a4590de6160d7787",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17f6917c770c487191855e56dd29d0ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Example usage (replace with your actual dataloader and num_classes)\n",
        "model = DETRLightningModule(num_classes=2)\n",
        "trainer = pl.Trainer(max_epochs=10, accelerator='gpu' if torch.cuda.is_available() else 'cpu')\n",
        "trainer.fit(model,dataloader, val_dataloader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yauNUtcTXbKr",
      "metadata": {
        "id": "yauNUtcTXbKr"
      },
      "source": [
        "## üìä Visualize Metrics and Predictions\n",
        "Plot or print the metrics after each epoch, and visualize sample predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ONMZQHsZXbKr",
      "metadata": {
        "id": "ONMZQHsZXbKr"
      },
      "outputs": [],
      "source": [
        "# üìä Plot mAP, Precision, and Recall per epoch from Lightning logs\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_metrics(trainer):\n",
        "    # Extract metrics from the trainer's logger\n",
        "    metrics = trainer.callback_metrics\n",
        "    epochs = range(1, trainer.current_epoch + 2)\n",
        "\n",
        "    # These keys may differ depending on your metric names/logs\n",
        "    mAP_50 = [metrics.get(f\"map_50_epoch_{e}\", None) for e in range(trainer.current_epoch + 1)]\n",
        "    mAP_95 = [metrics.get(f\"map_epoch_{e}\", None) for e in range(trainer.current_epoch + 1)]\n",
        "    precision = [metrics.get(f\"precision_epoch_{e}\", None) for e in range(trainer.current_epoch + 1)]\n",
        "    recall = [metrics.get(f\"recall_epoch_{e}\", None) for e in range(trainer.current_epoch + 1)]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, mAP_50, label=\"mAP@0.5\")\n",
        "    plt.plot(epochs, mAP_95, label=\"mAP@0.5:0.95\")\n",
        "    plt.plot(epochs, precision, label=\"Precision\")\n",
        "    plt.plot(epochs, recall, label=\"Recall\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Metric Value\")\n",
        "    plt.title(\"Detection Metrics per Epoch\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Usage example (run after training):\n",
        "# plot_metrics(trainer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "353bcbbb",
      "metadata": {
        "id": "353bcbbb"
      },
      "outputs": [],
      "source": [
        "# üñºÔ∏è Visualize sample predictions from the trained model\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_predictions(model, processor, dataloader, device, class_names, num_images=4, score_threshold=0.5):\n",
        "    model.eval()\n",
        "    images_shown = 0\n",
        "\n",
        "    for images, targets in dataloader:\n",
        "        # Move images to device\n",
        "        pixel_values = processor(images, return_tensors=\"pt\", padding=True).pixel_values.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(pixel_values=pixel_values)\n",
        "\n",
        "        # Post-process outputs\n",
        "        results = processor.post_process_object_detection(outputs, target_sizes=[img.size[::-1] for img in images], threshold=score_threshold)\n",
        "\n",
        "        for idx, (image, result) in enumerate(zip(images, results)):\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            plt.imshow(image)\n",
        "            ax = plt.gca()\n",
        "            boxes = result[\"boxes\"].cpu().numpy()\n",
        "            scores = result[\"scores\"].cpu().numpy()\n",
        "            labels = result[\"labels\"].cpu().numpy()\n",
        "\n",
        "            for box, score, label in zip(boxes, scores, labels):\n",
        "                xmin, ymin, xmax, ymax = box\n",
        "                ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color='red', linewidth=2))\n",
        "                ax.text(xmin, ymin, f'{class_names[label]}: {score:.2f}', bbox=dict(facecolor='yellow', alpha=0.5), fontsize=10, color='black')\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "            images_shown += 1\n",
        "            if images_shown >= num_images:\n",
        "                return\n",
        "\n",
        "# Usage example (after training):\n",
        "# class_names = [\"background\", \"smoke\"]  # adjust as needed\n",
        "# plot_predictions(model.model, model.processor, val_dataloader, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", class_names=class_names)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0472074cfa124513b46617943ee27aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d92f92a17fab48a3a776053692294c15",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_44a961cfcfb64405920150a2d40c823b",
            "value": "Sanity‚ÄáChecking‚ÄáDataLoader‚Äá0:‚Äá100%"
          }
        },
        "11eab0cc3d20479986357f4728129d0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "138668df96d8492d9d0347d7f9d5cba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14c2d9979e3847019da1fb3328f5fca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fba668a3e644425f98679e6f23af6361",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_138668df96d8492d9d0347d7f9d5cba6",
            "value": "‚Äá2/2‚Äá[00:02&lt;00:00,‚Äá‚Äá0.87it/s]"
          }
        },
        "1738b2fdd8884d26921250288850b17c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "17f6917c770c487191855e56dd29d0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3c1997eb7d545a88200d739ea692114",
              "IPY_MODEL_9c263877c2c944499f7f775b7110a92a",
              "IPY_MODEL_e9c9fc619365433093964ae52dce4d99"
            ],
            "layout": "IPY_MODEL_6534cc7812cd41f695cd32c306adab90"
          }
        },
        "2cb1bda7b82a4d4e8475a62839b2a0ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e6a63ef5f954c3a813ec43bfca7490e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44a961cfcfb64405920150a2d40c823b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58b1a2b123b24db082758785d9851ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6534cc7812cd41f695cd32c306adab90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "769bb51d27524d0bad244ee048850005": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "815c55147b0e4534bdc6ff5d83b35fca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "984033a2f5bf4a9d80eed0aa8f33dcce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c263877c2c944499f7f775b7110a92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11eab0cc3d20479986357f4728129d0c",
            "max": 7385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e6a63ef5f954c3a813ec43bfca7490e",
            "value": 0
          }
        },
        "a6403f74ff1a473eb6fd4434aaec9a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d57248cf39ed4127a4590de6160d7787": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0472074cfa124513b46617943ee27aa8",
              "IPY_MODEL_d66eee42c87d4604b4c90969027faf4c",
              "IPY_MODEL_14c2d9979e3847019da1fb3328f5fca6"
            ],
            "layout": "IPY_MODEL_1738b2fdd8884d26921250288850b17c"
          }
        },
        "d66eee42c87d4604b4c90969027faf4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_815c55147b0e4534bdc6ff5d83b35fca",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6403f74ff1a473eb6fd4434aaec9a4b",
            "value": 2
          }
        },
        "d92f92a17fab48a3a776053692294c15": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9c9fc619365433093964ae52dce4d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_984033a2f5bf4a9d80eed0aa8f33dcce",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2cb1bda7b82a4d4e8475a62839b2a0ef",
            "value": "‚Äá0/7385‚Äá[00:00&lt;?,‚Äá?it/s]"
          }
        },
        "f3c1997eb7d545a88200d739ea692114": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_769bb51d27524d0bad244ee048850005",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_58b1a2b123b24db082758785d9851ae7",
            "value": "Epoch‚Äá0:‚Äá‚Äá‚Äá0%"
          }
        },
        "fba668a3e644425f98679e6f23af6361": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
