{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4297929",
   "metadata": {},
   "source": [
    "## üì¶ Setup and Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers torchvision pycocotools opencv-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c041be",
   "metadata": {},
   "source": [
    "## üìö Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f686030d",
   "metadata": {},
   "source": [
    "## üîÅ Convert YOLO to COCO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67e30b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_to_coco(images_dir, labels_dir, output_json, category_name=\"smoke\"):\n",
    "    images = []\n",
    "    annotations = []\n",
    "    categories = [{\"id\": 1, \"name\": category_name}]\n",
    "    ann_id = 0\n",
    "    image_id = 0\n",
    "\n",
    "    for filename in sorted(os.listdir(images_dir)):\n",
    "        if not filename.endswith(\".jpg\"):\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(images_dir, filename)\n",
    "        label_path = os.path.join(labels_dir, filename.replace(\".jpg\", \".txt\"))\n",
    "        img = Image.open(image_path)\n",
    "        width, height = img.size\n",
    "\n",
    "        images.append({\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": filename,\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, \"r\") as f:\n",
    "                for line in f.readlines():\n",
    "                    cls_id, x_center, y_center, w, h = map(float, line.strip().split())\n",
    "                    x = (x_center - w / 2) * width\n",
    "                    y = (y_center - h / 2) * height\n",
    "                    w *= width\n",
    "                    h *= height\n",
    "\n",
    "                    annotations.append({\n",
    "                        \"id\": ann_id,\n",
    "                        \"image_id\": image_id,\n",
    "                        \"category_id\": 1,\n",
    "                        \"bbox\": [x, y, w, h],\n",
    "                        \"area\": w * h,\n",
    "                        \"iscrowd\": 0\n",
    "                    })\n",
    "                    ann_id += 1\n",
    "\n",
    "        image_id += 1\n",
    "\n",
    "    coco_dict = {\n",
    "        \"images\": images,\n",
    "        \"annotations\": annotations,\n",
    "        \"categories\": categories\n",
    "    }\n",
    "\n",
    "    with open(output_json, \"w\") as f:\n",
    "        json.dump(coco_dict, f, indent=2)\n",
    "\n",
    "    print(f\"COCO annotations saved to {output_json}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e25d586",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Convert Your Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a97c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these paths to your Kaggle or local environment\n",
    "images_dir = \"/kaggle/input/pyro_sdis_yolo/images\"\n",
    "labels_dir = \"/kaggle/input/pyro_sdis_yolo/labels\"\n",
    "output_json = \"/kaggle/working/train_annotations.json\"\n",
    "\n",
    "yolo_to_coco(images_dir, labels_dir, output_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c992bc",
   "metadata": {},
   "source": [
    "## üìÇ Load COCO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa16bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((800, 800)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = CocoDetection(\n",
    "    root=images_dir,\n",
    "    annFile=output_json,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=lambda x: list(zip(*x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31505900",
   "metadata": {},
   "source": [
    "## üß† Load Pretrained DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47100247",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce8c3f",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Train DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(3):  # Train for 3 epochs (adjust as needed)\n",
    "    for images, targets in data_loader:\n",
    "        encoding = processor(images=images, annotations=targets, return_tensors=\"pt\", padding=True)\n",
    "        encoding = {k: v.to(device) for k, v in encoding.items()}\n",
    "\n",
    "        outputs = model(**encoding)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Loss = {loss.item()}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"/kaggle/working/detr_smoke.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7c78fa",
   "metadata": {},
   "source": [
    "## üîç Inference and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "image_path = os.path.join(images_dir, os.listdir(images_dir)[0])\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "outputs = model(**inputs)\n",
    "target_sizes = torch.tensor([image.size[::-1]]).to(device)\n",
    "results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.8)[0]\n",
    "\n",
    "# Plot results\n",
    "plt.imshow(image)\n",
    "ax = plt.gca()\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    xmin, ymin, xmax, ymax = box\n",
    "    ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                               fill=False, color='red', linewidth=2))\n",
    "    ax.text(xmin, ymin, f\"{score:.2f}\", fontsize=12, color='white', bbox=dict(facecolor='red', alpha=0.5))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}